{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 문서의 내용을 읽는다\n",
    "2. 문서를 쪼갠다\n",
    "    - 토큰수 초과로 답변을 생성하지 못할 수 있고\n",
    "    - 문서가 길면 (인풋이 길면) 답변 생성이 오래걸림\n",
    "3. 임베딩 -> 벡터 데이터베이스에 저장\n",
    "4. 질문이 있을 때, 젝터 데이터베이스에 유사도 검색\n",
    "5. 유사도 검색으로 가져온 문서를 LLM에 질문과 같이 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet docx2txt langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 200,\n",
    ")\n",
    "\n",
    "loader = Docx2txtLoader('./tax.docx')\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#임베딩 OpenAIEmbeddings 사용\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "'''아래 실행하면 chroma라는 폴더가 생성되고 임베딩 된 데이터가 그곳에 생김\n",
    "chroma 는 인메모리(끄면 사라짐) 라서 persist_directory 의 파일로 저장'''\n",
    "#database = Chroma.from_documents(documents=document_list, embedding=embedding,collection_name='chroma-tax', persist_directory=\"./chroma\")\n",
    "\n",
    "database = Chroma(collection_name='chroma-tax', persist_directory=\"./chroma\", embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '연봉 5천만원인 직장인의 소득세는 얼마인가요?'\n",
    "#질문이 있으면 벡터 데이터베이스에 유사도 검색\n",
    "#retrieved_docs = database.similarity_search(query, k=3)\n",
    "#retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prompt = f\"\"\"[Identity]\n",
    "- 당신은 최고의 한국 소득세 전문가 입니다\n",
    "- [Context]를 참고해서 사용자의 질문에 답변해 주세요\n",
    "\n",
    "[Context]\n",
    "{retrieved_docs}\n",
    "\n",
    "Question : {query}\n",
    "\"\"\"'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ai_message = llm.invoke(prompt)\n",
    "\n",
    "#ai_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  c:\\Users\\softone\\llm-test\\.venv\\Scripts\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  c:\\Users\\softone\\llm-test\\.venv\\Scripts\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  c:\\Users\\softone\\llm-test\\.venv\\Scripts\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  c:\\Users\\softone\\llm-test\\.venv\\Scripts\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  c:\\Users\\softone\\llm-test\\.venv\\Scripts\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -u\n"
     ]
    }
   ],
   "source": [
    "%pip install -u langchain langchainhub —quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\softone\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=database.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ai_message = qa_chain({\"query\":query})\n",
    "ai_message = qa_chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '연봉 5천만원인 직장인의 소득세는 얼마인가요?',\n",
       " 'result': '죄송하지만, 제공된 정보에는 연봉 5천만원인 직장인의 소득세에 대한 구체적인 내용이 포함되어 있지 않습니다. 따라서 해당 질문에 대한 정확한 답변을 드릴 수 없습니다.'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
